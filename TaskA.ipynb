{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TaskA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YyC4Ap-zhIn"
      },
      "source": [
        "# **Task A**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chgMLOMJw_Hl"
      },
      "source": [
        "!apt-get update -qq > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX_abuLgxQms"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext(appName=\"YourTest\", master=\"local[*]\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpeXwSFtxZjT",
        "outputId": "baf3cdae-977d-49e0-895f-599e5ccb9dc0"
      },
      "source": [
        "!wget https://ndownloader.figshare.com/files/16188500 -q\n",
        "!tar -xvf 16188500\n",
        "!unzip -qn rumoureval2019/rumoureval-2019-training-data.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rumoureval2019/\n",
            "rumoureval2019/final-eval-key.json\n",
            "rumoureval2019/LICENSE\n",
            "rumoureval2019/home_scorer_macro.py\n",
            "rumoureval2019/README\n",
            "rumoureval2019/rumoureval-2019-training-data.zip\n",
            "rumoureval2019/rumoureval-2019-test-data.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfqqja-2yR9h"
      },
      "source": [
        "#### IMPORT ####\n",
        "\n",
        "from pyspark import SparkContext\n",
        "from pyspark.ml.feature import Tokenizer\n",
        "from pyspark.sql.functions import udf, col, expr, explode, struct, regexp_replace, collect_list, lit\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.ml.feature import * \n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.ml.linalg import VectorUDT, Vectors\n",
        "from functools import partial\n",
        "import re\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfl2Nuv7ykV8"
      },
      "source": [
        "spark = SparkSession.builder.appName(\"YourTest\").getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mMoYopvzgJ8"
      },
      "source": [
        "#### DOWNLOAD SOURCE TWEETS && REPLY TWEETS ###\n",
        "\n",
        "path = \"./rumoureval-2019-training-data/twitter-english/*/*/source-tweet/*.json\"\n",
        "source_tweets_df = spark.read.json(path)\n",
        "path = \"./rumoureval-2019-training-data/twitter-english/*/*/replies/*.json\"\n",
        "reply_tweets_df = spark.read.json(path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkhfJ5Xc0XXR"
      },
      "source": [
        "#### DOWNLOAD TRUE LABELS ###\n",
        "\n",
        "schema = StructType([StructField(\"subtaskaenglish\", MapType(StringType(), StringType())),StructField(\"subtaskbenglish\", MapType(StringType(), StringType()))])\n",
        "dev_key = spark.read.schema(schema).option(\"multiline\", \"true\").json('rumoureval-2019-training-data/dev-key.json')\n",
        "train_key = spark.read.schema(schema).option(\"multiline\", \"true\").json('rumoureval-2019-training-data/train-key.json')\n",
        "\n",
        "#### TRUE LABELS FOR TASK A ###\n",
        "\n",
        "dev_key_taskA = dev_key.select(explode(col(\"subtaskaenglish\")))\n",
        "train_key_taskA = train_key.select(explode(col(\"subtaskaenglish\")))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTaWQD_X0ou3"
      },
      "source": [
        "### DATA CLEANING  ##\n",
        "\n",
        "def clean(df):\n",
        "\n",
        "    def replace_url(text):\n",
        "        return re.sub(r'https?:\\/\\/.*[\\r\\n]*', 'url_url_url', text, flags=re.MULTILINE)\n",
        "\n",
        "    replace_url_udf = udf(replace_url, StringType())\n",
        "\n",
        "    df = df.withColumn('cleaned_text', replace_url_udf(col('text')))\n",
        "\n",
        "    ### REMOVE @\n",
        "    \n",
        "    df = df.withColumn('cleaned_text', regexp_replace(col('cleaned_text'), r'(@([A-Za-z0-9]+))', ''))\n",
        "\n",
        "    return df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSD8hGgS1AbG"
      },
      "source": [
        "words_dict = dict(\n",
        "      has_belief_words = set(\"assume believe apparent per-haps suspect think thought consider\".split()),\n",
        "      has_report_words = set(\"evidence source official footage capture assert told claim according\".split()),\n",
        "      has_doubt_words = set(\"wonder allege unsure guess speculate doubt\".split()),\n",
        "      has_knowledge = set(\"confirm definitely admit\".split()),\n",
        "      has_denial_words = set(\"refuse reject rebuff dismiss contradict oppose\".split()),\n",
        "      has_curse_words = set(\"lol rofl lmfao yeah stfu aha wtf shit\".split()),\n",
        "      has_question_words = set(\"when which what who how whom why whose\".split()),\n",
        "      has_other_words = set(\"irresponsible careless liar false witness untrue neglect integrity murder fake\".split())\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiWIVNPy1lNJ"
      },
      "source": [
        "## FEATURE EXTRACTION ##\n",
        "\n",
        "def extract_features(df):\n",
        "    hasqmark = udf(lambda x: int('?' in x), IntegerType())\n",
        "    df = df.withColumn('hasqmark', hasqmark(col('cleaned_text')))\n",
        "\n",
        "    hasmark = udf(lambda x: int('!' in x), IntegerType())\n",
        "    df = df.withColumn('hasmark', hasmark(col('cleaned_text')))\n",
        "\n",
        "    hasperiod = udf(lambda x: int('.' in x), IntegerType())\n",
        "    df = df.withColumn('hasperiod', hasperiod(col('cleaned_text')))\n",
        "\n",
        "    df = df.withColumn('hashtags_count', expr('size(entities.hashtags)'))\n",
        "\n",
        "    df = df.withColumn('mentions_count', expr('size(entities.user_mentions)'))\n",
        "\n",
        "    df = df.withColumn('hasurls', expr('cast(size(entities.urls) >= 1 AS int)'))\n",
        "\n",
        "    df = df.withColumn('hasmedia', expr('cast(size(entities.media) >= 1 AS int)'))\n",
        "\n",
        "    df = df.withColumn('friends_count', expr('user.friends_count'))\n",
        "\n",
        "    df = df.withColumn('followers_count', expr('user.followers_count'))\n",
        "\n",
        "    ratiocapital = udf(lambda x: sum(map(str.isupper, x))/(len(x)+1), FloatType())\n",
        "    df = df.withColumn('ratiocapital', ratiocapital(col('cleaned_text')))\n",
        "\n",
        "    charlen = udf(lambda x: len(x), IntegerType())\n",
        "    df = df.withColumn('charlen', charlen(col('cleaned_text')))\n",
        "\n",
        "    df = df.withColumn('issource', expr('CAST((in_reply_to_status_id IS NULL) AS INT)'))\n",
        "\n",
        "    ## TOKENIZATION ##\n",
        "\n",
        "    tokenizer = Tokenizer(inputCol=\"cleaned_text\", outputCol=\"words\")\n",
        "    temp_df = tokenizer.transform(df)\n",
        "\n",
        "    #TODO remove stop words?\n",
        "\n",
        "    remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "    df = remover.transform(temp_df)\n",
        "\n",
        "    hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawhashtf\", numFeatures=100)\n",
        "    df = hashingTF.transform(df)\n",
        "\n",
        "    idf = IDF(inputCol=\"rawhashtf\", outputCol=\"hashtf\")\n",
        "    idfModel = idf.fit(df)\n",
        "    df = idfModel.transform(df)\n",
        "\n",
        "    ## TOKEN FEATURE EXTRACTION ##\n",
        "    wordlen = udf(lambda words: len(words), IntegerType())\n",
        "    df = df.withColumn('wordlen', wordlen(col('words')))\n",
        "\n",
        "    def contains(y, x):\n",
        "      return int(bool(len(y.intersection(set(x)))))\n",
        "\n",
        "    for name, ys in words_dict.items():\n",
        "        df = df.withColumn(name, udf(partial(contains, ys), IntegerType())(col('words')))\n",
        "\n",
        "    #TODO negation words etc.\n",
        "    negationwords = ['not', 'no', 'nobody', 'nothing', 'none', 'never',\n",
        "              'neither', 'nor', 'nowhere', 'hardly', 'scarcely',\n",
        "              'barely', 'don', 'isn', 'wasn', 'shouldn', 'wouldn',\n",
        "              'couldn', 'doesn']\n",
        "    def negacount(words):\n",
        "      c = 0\n",
        "      for negationword in negationwords:\n",
        "        if negationword in words:\n",
        "          c += 1\n",
        "      return c\n",
        "    negationcount = udf(negacount, IntegerType())\n",
        "    df = df.withColumn('hasnegation', negationcount(col('words')))\n",
        "\n",
        "    @udf('float')\n",
        "    def count_upper(x):\n",
        "        a = x.split()\n",
        "        return sum(map(str.isupper, a))/(len(a) + 1)\n",
        "\n",
        "    df = df.withColumn('allcapsratio', count_upper(col('cleaned_text')))\n",
        "\n",
        "    return df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03H5Uh4e1-XJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ffba5c-760d-47fc-f1f0-097e144134aa"
      },
      "source": [
        "source_preprocessed = extract_features(clean(source_tweets_df))\n",
        "reply_preprocessed = extract_features(clean(reply_tweets_df))\n",
        "print(source_preprocessed.count())\n",
        "print(reply_preprocessed.count())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "325\n",
            "5243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ5BRU5Z2Eb2"
      },
      "source": [
        "all_features = \"\"\"hasmark hasqmark hasperiod hashtags_count mentions_count hasurls hasmedia\n",
        "ratiocapital charlen issource wordlen hasnegation allcapsratio hashtf\n",
        "favorite_count friends_count followers_count\"\"\".split() + list(words_dict.keys())\n",
        "reply_features = []"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HulSoVeM2M7D"
      },
      "source": [
        "train_tweets = reply_preprocessed.select(['id'] + all_features + reply_features).union(\n",
        "        source_preprocessed.select(['id'] + all_features + reply_features)\n",
        "    )\n",
        "train_all = train_key_taskA.withColumnRenamed('key', 'id').withColumnRenamed('value', 'label').join(train_tweets, 'id'\n",
        ")\n",
        "\n",
        "dev_tweets =   reply_preprocessed.select(['id'] + all_features + reply_features).union(\n",
        "       source_preprocessed.select(['id'] + all_features + reply_features) \n",
        ")\n",
        "\n",
        "dev = dev_key_taskA.withColumnRenamed('key', 'id').withColumnRenamed('value', 'label').join( dev_tweets, 'id'\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kah-gE_h2W5Q",
        "outputId": "870eabcc-31bc-4660-c08b-7d0acc56207a"
      },
      "source": [
        "print(train_key_taskA.count())\n",
        "print(train_tweets.count())\n",
        "print(train_all.count())\n",
        "print(dev_key_taskA.count())\n",
        "print(dev_tweets.count())\n",
        "print(dev.count())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5217\n",
            "5568\n",
            "4519\n",
            "1485\n",
            "5568\n",
            "1049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ1hMoiC2hB7"
      },
      "source": [
        "# ML TEST\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "371WfPK83JWN"
      },
      "source": [
        "inputCols = \"\"\"hasmark hasqmark hasperiod hashtags_count mentions_count hasurls\n",
        "ratiocapital charlen issource wordlen hasnegation allcapsratio\"\"\".split() + list(words_dict.keys())\n",
        "\n",
        "assembler = VectorAssembler(inputCols=inputCols,outputCol=\"features\")\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures', withStd=True, withMean=False)\n",
        "indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
        "pipeline = Pipeline(stages=[assembler, scaler, indexer])\n",
        "\n",
        "processor = pipeline.fit(train_all)\n",
        "\n",
        "temp = processor.transform(train_all)\n",
        "train_all_features_df = temp.select(['features', 'label_index'])\n",
        "\n",
        "temp = processor.transform(dev)\n",
        "dev_features_df = temp.select(['features', 'label_index'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2BOoeQIBTI9"
      },
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator, TrainValidationSplitModel\n",
        "lr = LogisticRegression(labelCol='label_index', maxIter=10)\n",
        "paramGrid = ParamGridBuilder()\\\n",
        "    .addGrid(lr.regParam, [0.01, 0.001]) \\\n",
        "    .addGrid(lr.fitIntercept, [False, True])\\\n",
        "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
        "paramGrid = paramGrid.build()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvcD0gYAB3V9"
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(metricName=\"f1\", labelCol='label_index')\n",
        "# tvs = TrainValidationSplit(estimator=lr,\n",
        "#                            estimatorParamMaps=paramGrid,\n",
        "#                            evaluator=evaluator,\n",
        "#                            # 80% of the data will be used for training, 20% for validation.\n",
        "#                            trainRatio=0.8)\n",
        "\n",
        "tvs = CrossValidator(estimator=lr,\n",
        "                           estimatorParamMaps=paramGrid,\n",
        "                           evaluator=evaluator,\n",
        "                           # 80% of the data will be used for training, 20% for validation.\n",
        "                           numFolds=3)\n",
        "# tvs = LogisticRegression(labelCol='label_index', maxIter=10, regParam=0.001)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysodEkEQ3aK2"
      },
      "source": [
        "# train model\n",
        "# model = trainer.fit(train_all_features_df, )\n",
        "model = tvs.fit(train_all_features_df)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIQF1RFg3f3p"
      },
      "source": [
        "# # compute f1 on the dev set\n",
        "# result = model.transform(dev_features_df)\n",
        "# predictionAndLabels = result.select(\"prediction\", \"label_index\")\n",
        "\n",
        "# print(\"Test set f1 = \" + str(evaluator.evaluate(predictionAndLabels)))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f50fCo6i3qbY",
        "outputId": "28077856-5541-47cb-8f8e-c39c3d0a7a63"
      },
      "source": [
        "result = model.transform(dev_features_df)\n",
        "y_true = result.select(['label_index']).collect()\n",
        "y_pred = result.select(['prediction']).collect()\n",
        "print(classification_report(y_true, y_pred, digits=3))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.799     0.955     0.870       778\n",
            "         1.0      0.683     0.298     0.415        94\n",
            "         2.0      0.615     0.453     0.522       106\n",
            "         3.0      0.000     0.000     0.000        71\n",
            "\n",
            "    accuracy                          0.781      1049\n",
            "   macro avg      0.524     0.426     0.452      1049\n",
            "weighted avg      0.716     0.781     0.735      1049\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv3KMrqcQ9YW"
      },
      "source": [
        "best_params = {param[0].name: param[1] for param in model.bestModel.extractParamMap().items()}\n",
        "best_lr = LogisticRegression(**best_params)\n",
        "best_model = best_lr.fit(train_all_features_df)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx5tihoYS2yD",
        "outputId": "af527406-e604-40d0-c457-570f30073511"
      },
      "source": [
        "result = best_model.transform(dev_features_df)\n",
        "y_true = result.select(['label_index']).collect()\n",
        "y_pred = result.select(['prediction']).collect()\n",
        "print(classification_report(y_true, y_pred, digits=3))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.799     0.955     0.870       778\n",
            "         1.0      0.683     0.298     0.415        94\n",
            "         2.0      0.615     0.453     0.522       106\n",
            "         3.0      0.000     0.000     0.000        71\n",
            "\n",
            "    accuracy                          0.781      1049\n",
            "   macro avg      0.524     0.426     0.452      1049\n",
            "weighted avg      0.716     0.781     0.735      1049\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra0W8Lvb3BBO"
      },
      "source": [
        "# model.write().overwrite().save('subtaskA_model')\n",
        "all_pipeline = Pipeline(stages=[processor, best_model])\n",
        "!rm -rf subtaskA_model/\n",
        "all_pipeline.write().overwrite().save('subtaskA_model')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-jv859L3D1T"
      },
      "source": [
        "!zip -rq subtaskA_model subtaskA_model/"
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}